{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPU Version: 2.0.0\n",
      "Eager Execution is: True\n",
      "Keras Version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- check tensorflow and keras version\n",
    "'''\n",
    "print(f'Tensorflow GPU Version: {tf.__version__}')\n",
    "print(f'Eager Execution is: {tf.executing_eagerly()}')\n",
    "print(f'Keras Version: {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- check GPU \n",
    "'''\n",
    "var = tf.Variable([3,3])\n",
    "if tf.test.is_gpu_available():\n",
    "    print('Running on GPU')\n",
    "else:\n",
    "    print('Runing on CPU')\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- MLP layer\n",
    "'''\n",
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=3, activation=None, trainable=True, name=None, dtype=tf.float32, **kwargs):\n",
    "        super(MLP, self).__init__( name=name, trainable = trainable, dtype=dtype, **kwargs)\n",
    "        self.units = units\n",
    "        self.__activation_name = activation\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),initializer='random_normal',)\n",
    "        self.b = self.add_weight(shape=(self.units,),initializer='random_normal')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config_dic ={\n",
    "            'units':self.units,\n",
    "            'activation': self.__activation_name, \n",
    "            'trainable_weights & bias':self.trainable_weights,\n",
    "            'non-trainable_weights & bias':self.non_trainable_weights,\n",
    "        }\n",
    "        config = super(MLP,self).get_config()\n",
    "        config.update(config_dic)\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs, training = None):\n",
    "        if tf.rank(inputs)==1:\n",
    "            inputs = tf.keras.backend.expand_dims(inputs, axis=0)\n",
    "        linear_combination = tf.matmul(inputs, self.w)+self.b \n",
    "        return self.activation(linear_combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- subclass model\n",
    "'''\n",
    "class MLP_Model(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP_Model, self).__init__(self, **kwargs)\n",
    "        self.mlp1 = MLP(256, activation='sigmoid')\n",
    "        self.mlp2 = MLP(128, activation='sigmoid')\n",
    "        self.mlp3 = MLP(10, acitivation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        opt = self.mlp1(inputs)\n",
    "        opt = self.mlp2(opt)\n",
    "        opt = self.mlp3(opt)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- logistic regression\n",
    "- perform binary classification with multi-labels\n",
    "'''\n",
    "class LogisticRegression(tf.keras.Model):\n",
    "    def __init__(self,labels=1, **kwargs):\n",
    "        super(LogisticRegression, self).__init__(self, **kwargs)\n",
    "        self.label = labels\n",
    "        self.lglayer = MLP(labels, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        opt= self.lglayer(inputs)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression(labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable([[40, 30, 20, 10], [10, 20, 30, 40]],dtype=tf.float32)\n",
    "k_value, k_index = tf.math.top_k(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[40., 30.],\n",
       "       [40., 30.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [3, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
