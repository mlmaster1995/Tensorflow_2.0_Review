{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0.0 Basics Review\n",
    "## - tf variables\n",
    "## - tf operations\n",
    "## - tf keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPU Version: 2.0.0\n",
      "Eager Execution is: True\n",
      "Keras Version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- check tensorflow and keras version\n",
    "'''\n",
    "print(f'Tensorflow GPU Version: {tf.__version__}')\n",
    "print(f'Eager Execution is: {tf.executing_eagerly()}')\n",
    "print(f'Keras Version: {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- check GPU \n",
    "'''\n",
    "var = tf.Variable([3,3])\n",
    "if tf.test.is_gpu_available():\n",
    "    print('Running on GPU')\n",
    "else:\n",
    "    print('Runing on CPU')\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf1:  <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.6>\n",
      "tf2:  <tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
      "array([[0, 4, 5],\n",
      "       [4, 2, 7],\n",
      "       [7, 8, 9]], dtype=int32)>\n",
      "tf1 iwth Numpy: 5.599999904632568\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Declare variables\n",
    "'''\n",
    "var = 56\n",
    "tf1 = tf.Variable(var, dtype=tf.float32)\n",
    "tf1.assign(5.6)\n",
    "tf2 = tf.Variable([[0,4,5],[4,2,7],[7,8,9]])\n",
    "print('tf1: ',tf1)\n",
    "print('tf2: ',tf2)\n",
    "print(f'tf1 iwth Numpy: {tf1.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(568, shape=(), dtype=int16)\n",
      "568\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Declare Constants\n",
    "'''\n",
    "constantVar = tf.constant(568, dtype = tf.int16)\n",
    "print(constantVar)\n",
    "print(constantVar.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var shape: (3, 4)\n",
      "var1 shape: (2, 6)\n",
      "var2 shape: (1, 12)\n",
      "var3 shape: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Reshape a tensor\n",
    "'''\n",
    "var = tf.Variable([[2,3,4,5],[5,2,9,0],[3,1,2,4]], dtype=tf.float32)\n",
    "print('var shape:',var.shape)\n",
    "var1 = tf.reshape(var,(2,6))\n",
    "print('var1 shape:',var1.shape)\n",
    "var2 = tf.reshape(var, (1,12))\n",
    "print('var2 shape:',var2.shape)\n",
    "var3 = tf.reshape(var, (4,3))\n",
    "print('var3 shape:',var3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var rank: tf.Tensor(3, shape=(), dtype=int32)\n",
      "var2 slice: tf.Tensor(\n",
      "[[[ 2.  3.  4.  5.]\n",
      "  [ 5.  2.  9.  0.]\n",
      "  [ 3.  1.  2.  4.]]\n",
      "\n",
      " [[ 0. 30. 40. 50.]\n",
      "  [ 5.  2.  9.  0.]\n",
      "  [ 3.  1.  2.  4.]]], shape=(2, 3, 4), dtype=float32)\n",
      "var2 rank: 3\n",
      "var2 size: 24\n",
      "var2 dtype: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tensor dimention\n",
    "- tensor slice\n",
    "- tensor cast numpy\n",
    "- tensor slice\n",
    "- tensor dtype\n",
    "'''\n",
    "var = tf.Variable([[[2,3,4,5],[5,2,9,0],[3,1,2,4]],[[0,30,40,50],[5,2,9,0],[3,1,2,4]],[[12,13,14,15],[5,2,9,0],[3,1,2,4]]], dtype=tf.float32)\n",
    "print('var rank:',tf.rank(var))\n",
    "var2 = var[0:2]\n",
    "print('var2 slice:',var2)\n",
    "print('var2 rank:',tf.rank(var2).numpy())\n",
    "print('var2 size:',tf.size(var2).numpy())\n",
    "print('var2 dtype:', var2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var tensor:\n",
      " tf.Tensor(\n",
      "[[[  4.   6.   8.  10.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]\n",
      "\n",
      " [[  0.  60.  80. 100.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]\n",
      "\n",
      " [[ 24.  26.  28.  30.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]], shape=(3, 3, 4), dtype=float32)\n",
      "\n",
      "var numpy cast:\n",
      " [[[  4.   6.   8.  10.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]\n",
      "\n",
      " [[  0.  60.  80. 100.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]\n",
      "\n",
      " [[ 24.  26.  28.  30.]\n",
      "  [ 10.   4.  18.   0.]\n",
      "  [  6.   2.   4.   8.]]]\n",
      "\n",
      "var*4:\n",
      " tf.Tensor(\n",
      "[[[ 16.  24.  32.  40.]\n",
      "  [ 40.  16.  72.   0.]\n",
      "  [ 24.   8.  16.  32.]]\n",
      "\n",
      " [[  0. 240. 320. 400.]\n",
      "  [ 40.  16.  72.   0.]\n",
      "  [ 24.   8.  16.  32.]]\n",
      "\n",
      " [[ 96. 104. 112. 120.]\n",
      "  [ 40.  16.  72.   0.]\n",
      "  [ 24.   8.  16.  32.]]], shape=(3, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tensor element-wise primitive tensor operations\n",
    "- tensor broadcasting\n",
    "'''\n",
    "var1 = tf.Variable([[[2,3,4,5],[5,2,9,0],[3,1,2,4]],[[0,30,40,50],[5,2,9,0],[3,1,2,4]],[[12,13,14,15],[5,2,9,0],[3,1,2,4]]], dtype=tf.float32)\n",
    "var2 = tf.Variable([[[2,2,2,2],[2,2,2,2],[2,2,2,2]],[[2,2,2,2],[2,2,2,2],[2,2,2,2]],[[2,2,2,2],[2,2,2,2],[2,2,2,2]]], dtype=tf.float32)\n",
    "var = var1 * var2\n",
    "print('var tensor:\\n',var)\n",
    "print('\\nvar numpy cast:\\n',var.numpy())\n",
    "print('\\nvar*4:\\n',var*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var:\n",
      " tf.Tensor(\n",
      "[[14 23]\n",
      " [23 50]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "var dtype: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tensor multiplication\n",
    "- tensor constant\n",
    "- tensor constant cast\n",
    "'''\n",
    "var1 = tf.constant([[1,2,3],[4,5,3]])\n",
    "var2 = tf.constant([[1,2,3],[4,5,3]])\n",
    "var = tf.matmul(var1,tf.transpose(var2))\n",
    "print('var:\\n',var)\n",
    "var = tf.cast(var, dtype=tf.float32)\n",
    "print('\\nvar dtype:', var.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[1.0, 2.0, 4.0], [], [3.0, 4.0], [1.0]]>\n",
      "tf.Tensor([1. 2. 4.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "<tf.RaggedTensor [[1, 2, 4], [], [5, 6], [7], [8]]>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- ragged tensors by constant\n",
    "- ragged tensors by split_row\n",
    "'''\n",
    "ragged_tensor = tf.ragged.constant([[1,2,4],[],[3,4],[1]], dtype=tf.float32, name='ragged_tensor')\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor[0])\n",
    "print(ragged_tensor[3])\n",
    "ragged_tensor2 = tf.RaggedTensor.from_row_splits(values=[1,2,4,5,6,7,8], row_splits=[0,3,3,5,6,7])\n",
    "print(ragged_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_t1:\n",
      " tf.Tensor(\n",
      "[[0.23302452]\n",
      " [0.33036613]\n",
      " [0.07002912]], shape=(3, 1), dtype=float32)\n",
      "_t2:\n",
      " tf.Tensor(\n",
      "[[-1.1006709 ]\n",
      " [-0.40500164]\n",
      " [-1.2100329 ]], shape=(3, 1), dtype=float32)\n",
      "_t:\n",
      " tf.Tensor(\n",
      "[[1.7787435 ]\n",
      " [0.54076576]\n",
      " [1.638559  ]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- calculate square differences\n",
    "'''\n",
    "t1 = tf.random.normal((3,1))\n",
    "t2 = tf.random.normal((3,1))\n",
    "t = tf.math.squared_difference(t1,t2,name='square_difference')\n",
    "print('_t1:\\n',t1)\n",
    "print('_t2:\\n',t2)\n",
    "print('_t:\\n',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_var:\n",
      " tf.Tensor(\n",
      "[[8.844145   8.424911   5.7227373 ]\n",
      " [4.715581   8.562659   7.411667  ]\n",
      " [0.57933927 8.567917   4.0922523 ]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "_cross_mean:\n",
      " tf.Tensor(6.324579, shape=(), dtype=float32)\n",
      "\n",
      "_x_mean:\n",
      " tf.Tensor([4.7130218 8.518496  5.7422185], shape=(3,), dtype=float32)\n",
      "\n",
      "_x_mean_same_dim:\n",
      " tf.Tensor([[4.7130218 8.518496  5.7422185]], shape=(1, 3), dtype=float32)\n",
      "\n",
      "_y_mean:\n",
      " tf.Tensor([7.6639304 6.8966355 4.4131694], shape=(3,), dtype=float32)\n",
      "\n",
      "_y_mean_same_dim:\n",
      " tf.Tensor(\n",
      "[[7.6639304]\n",
      " [6.8966355]\n",
      " [4.4131694]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- calculate tensor mean\n",
    "'''\n",
    "var = tf.constant(tf.random.uniform((3,3),minval=0, maxval= 10, dtype=tf.float32))\n",
    "cross_mean = tf.reduce_mean(var, axis=None)\n",
    "x_mean = tf.reduce_mean(var, axis=0)\n",
    "y_mean = tf.reduce_mean(var, axis=1)\n",
    "x_mean_dim = tf.reduce_mean(var, axis=0,keepdims=True)\n",
    "y_mean_dim = tf.reduce_mean(var, axis=1, keepdims=True)\n",
    "print('_var:\\n',var)\n",
    "print('\\n_cross_mean:\\n',cross_mean)\n",
    "print('\\n_x_mean:\\n',x_mean)\n",
    "print('\\n_x_mean_same_dim:\\n',x_mean_dim)\n",
    "print('\\n_y_mean:\\n',y_mean)\n",
    "print('\\n_y_mean_same_dim:\\n',y_mean_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_random_var1:\n",
      " tf.Tensor(\n",
      "[[ 0.43616885]\n",
      " [-1.9093795 ]\n",
      " [ 1.3789066 ]\n",
      " [-1.0405852 ]], shape=(4, 1), dtype=float32)\n",
      "_random_var2:\n",
      " tf.Tensor(\n",
      "[[ 4.6377807]\n",
      " [14.660629 ]\n",
      " [-6.065405 ]\n",
      " [ 7.9940577]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tensors with random normal values\n",
    "'''\n",
    "tf.random.set_seed(2)\n",
    "var_random1 = tf.random.normal((4,1),mean=0,stddev=1)\n",
    "var_random2 = tf.random.normal((4,1),mean=5,stddev=10)\n",
    "print('_random_var1:\\n',var_random1)\n",
    "print('_random_var2:\\n',var_random2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_var1: tf.Tensor(\n",
      "[[3]\n",
      " [1]\n",
      " [3]\n",
      " [1]], shape=(4, 1), dtype=int32)\n",
      "_var2: tf.Tensor(\n",
      "[[7]\n",
      " [5]\n",
      " [7]\n",
      " [7]], shape=(4, 1), dtype=int32)\n",
      "_var_concat_x: tf.Tensor(\n",
      "[[3]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [7]], shape=(8, 1), dtype=int32)\n",
      "_var_concat_y: tf.Tensor(\n",
      "[[3 7]\n",
      " [1 5]\n",
      " [3 7]\n",
      " [1 7]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tensors with random uniform values\n",
    "'''\n",
    "tf.random.set_seed(2)\n",
    "var1 = tf.random.uniform((4,1),minval=1, maxval=4, dtype=tf.int32)\n",
    "var2 = tf.random.uniform((4,1),minval=5, maxval=8, dtype=tf.int32)\n",
    "var_concat_x = tf.concat(values=[var1,var2],axis=0)\n",
    "var_concat_y = tf.concat(values=[var1,var2],axis=1)\n",
    "print('_var1:',var1)\n",
    "print('_var2:',var2)\n",
    "print('_var_concat_x:',var_concat_x)\n",
    "print('_var_concat_y:',var_concat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_var:\n",
      " tf.Tensor(\n",
      "[[ 4  7  1  3  4  8  8  5  2  0]\n",
      " [ 6  4  0  9  4  3 -2  2  5 -1]\n",
      " [ 3  4  8  0 -1  5  0  8  4  7]\n",
      " [ 8  2  9  7  0  5  7  8  1  2]\n",
      " [ 3  1 -1  9 -2  5  2  7 -2  0]\n",
      " [ 3  8 -1 -2  8  1  5  7  5  6]\n",
      " [ 0  9 -2  3  8  3  4  0  4  0]\n",
      " [ 0  9  2  3  8  1  1  3  1  4]\n",
      " [-2  5  4  6 -2 -1  0  2  0  7]\n",
      " [-2  1  8  6 -2  4  3  6  4  0]], shape=(10, 10), dtype=int32)\n",
      "_max_index_x:\n",
      " [3 6 3 1 5 0 0 2 1 2]\n",
      "_min_index_y:\n",
      " [9 6 4 4 4 3 2 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- indexing tensor values\n",
    "- defualt axis=None, it's across cols to search max or min\n",
    "'''\n",
    "tf.random.set_seed(1)\n",
    "var = tf.constant(tf.random.uniform((10,10), minval=-2, maxval=10, dtype=tf.int32))\n",
    "_max_index_x = tf.argmax(input = var, axis=0, output_type=tf.int32)\n",
    "_min_index_y = tf.argmin(input = var, axis=1, output_type=tf.int32)\n",
    "print('_var:\\n', var)\n",
    "print('_max_index_x:\\n',_max_index_x.numpy())\n",
    "print('_min_index_y:\\n',_min_index_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff7aaa56d10>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "-?????????????????????//\n",
    "- Checkpoint to restore and save tensors\n",
    "- Checkpoint's constructor accepts keyword arguments whose values are types that contain trackable state, such as \n",
    "  ~`tf.keras.optimizers.Optimizer` implementations, \n",
    "  ~`tf.Variable`, \n",
    "  ~`tf.keras.Layer` implementations,\n",
    "  ~`tf.keras.Model` implementations. \n",
    "  It saves these values with a checkpoint and maintains a `save_counter` for numbering checkpoints\n",
    "'''\n",
    "var = tf.Variable([[1,2],[3,4]])\n",
    "checkpoint = tf.train.Checkpoint(var=var)\n",
    "path = checkpoint.save('./tf_ckpts/')\n",
    "var = var.assign([[3,3,],[5,5]])\n",
    "checkpoint.restore(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tf.function(\n",
    "    func=None, input_signature=None, autograph=True, experimental_implements=None,\n",
    "    experimental_autograph_options=None, experimental_relax_shapes=False,\n",
    "    experimental_compile=None\n",
    ")\n",
    "\n",
    "'''\n",
    "def calc(x,y):\n",
    "    return x**2*5+y\n",
    "f1 = tf.function(test)\n",
    "print(f1(2,3))\n",
    "\n",
    "@tf.function\n",
    "def calc_2(x,y):\n",
    "    return x*6+y\n",
    "print(calc_2(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf keras modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4445, shape=(2, 2), dtype=float16, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float16)>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- declare a variable with backend\n",
    "- Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle low-level operations such as tensor products, convolutions and so on itself. \n",
    "- Instead, it relies on a specialized, well optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the \n",
    "implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n",
    "'''\n",
    "var = K.constant([[1,2],[3,4]],dtype=tf.float16)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- load minist data\n",
    "'''\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x, train_y),(test_x, test_y)=mnist.load_data()\n",
    "train_x = train_x.astype('float32')/255\n",
    "test_x =test_x.astype('float32')/255\n",
    "train_x = train_x.reshape(train_x.shape[0],28,28,1)\n",
    "test_x = test_x.reshape(test_x.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 87,562\n",
      "Trainable params: 87,370\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tf.keras Functional API\n",
    "'''\n",
    "ipt = tf.keras.Input(shape=(28,28,1))\n",
    "opt = tf.keras.layers.Conv2D(32,3)(ipt)\n",
    "opt = tf.keras.layers.LeakyReLU()(opt)\n",
    "opt = tf.keras.layers.BatchNormalization()(opt)\n",
    "opt = tf.keras.layers.MaxPool2D((3,3))(opt)\n",
    "\n",
    "opt = tf.keras.layers.Conv2D(64,3)(opt)\n",
    "opt = tf.keras.layers.LeakyReLU()(opt)\n",
    "opt = tf.keras.layers.BatchNormalization()(opt)\n",
    "opt = tf.keras.layers.MaxPool2D((3,3))(opt)\n",
    "\n",
    "opt = tf.keras.layers.Flatten()(opt)\n",
    "opt = tf.keras.layers.Dense(256, activation='relu')(opt)\n",
    "opt = tf.keras.layers.Dense(10, activation='softmax')(opt)\n",
    "\n",
    "model = tf.keras.models.Model(ipt, opt)\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1646 - acc: 0.9532 - val_loss: 0.2478 - val_acc: 0.9220\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0399 - val_acc: 0.9858\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0335 - acc: 0.9891 - val_loss: 0.0390 - val_acc: 0.9874\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0350 - val_acc: 0.9889\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0549 - val_acc: 0.9819\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0202 - acc: 0.9931 - val_loss: 0.0441 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0338 - val_acc: 0.9894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0144 - acc: 0.9952 - val_loss: 0.0409 - val_acc: 0.9887\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0354 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67f063e350>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_x, \n",
    "    train_y,\n",
    "    batch_size = 128,\n",
    "    epochs = 10,\n",
    "    validation_data=(test_x,test_y),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- tf.keras.Model class\n",
    "- tf.keras.callbacks.Callback class\n",
    "- tf.keras.callbacks.EarlyStopping class\n",
    "'''\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32,(3,3), padding='same')\n",
    "        self.act1 = tf.keras.layers.LeakyReLU()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((3,3))\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(32,(3,3), padding='same')\n",
    "        self.act2 = tf.keras.layers.LeakyReLU()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((3,3))\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.act1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    \n",
    "class customCallback(tf.keras.callbacks.Callback):\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        # parent constructor\n",
    "        super(customCallback,self).__init__()\n",
    "        \n",
    "    # call at the training end    \n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        print('\\n train_acc-val_acc:',logs['acc']-logs['val_acc'])\n",
    "        print(self.params)\n",
    "\n",
    "'''\n",
    "ValAccEarlyStopping Class:\n",
    "- val_acc_base is to define the expected val_acc at the end of each epoch traning\n",
    "- if val_acc >= val_acc_base, model will stop training\n",
    "- if early stopping is not triggered by the end of training, the model with best \n",
    "val_acc will be restored\n",
    "'''\n",
    "class ValAccEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    # constructor\n",
    "    def __init__(self, val_acc_base):\n",
    "        # parent constructor\n",
    "        super(ValAccEarlyStopping,self).__init__(monitor='val_acc', verbose=1, baseline=val_acc_base, restore_best_weights=True)\n",
    "        # fields\n",
    "        self.__best_weights=None\n",
    "        self.__bestWeightEpoch=None\n",
    "        self.__weights =[]\n",
    "        self.__val_acc=[]\n",
    "        \n",
    "    # early stopping method\n",
    "    def on_epoch_end(self,epoch,logs=None): \n",
    "        # restore best model weights\n",
    "        if self.restore_best_weights:\n",
    "            # save weights & val_acc for each epoch\n",
    "            self.__weights.append(self.model.get_weights())\n",
    "            self.__val_acc.append(logs['val_acc'])\n",
    "            \n",
    "            # update the best weights\n",
    "            self.__bestWeightEpoch = self.__val_acc.index(max(self.__val_acc))\n",
    "            self.__best_weights = self.__weights[self.__bestWeightEpoch]           \n",
    "        \n",
    "        # early stopping check\n",
    "        if logs[self.monitor]>=self.baseline:\n",
    "            self.model.stop_training = True\n",
    "            self.stopped_epoch = epoch+1\n",
    "        \n",
    "    # update early stopping training end method         \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "        else:\n",
    "            self.model.set_weights(self.__best_weights)\n",
    "            print(f'Early stopping is not triggered, but best model is restored at epoch {self.__bestWeightEpoch+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1619 - acc: 0.9514 - val_loss: 0.1679 - val_acc: 0.9587\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0498 - acc: 0.9843 - val_loss: 0.0428 - val_acc: 0.9859\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6614d91290>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- build model \n",
    "- compile model\n",
    "- train model with custom early stopping class\n",
    "'''\n",
    "model = MyModel()\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics= ['acc'],\n",
    ")\n",
    "model.fit(\n",
    "    train_x, \n",
    "    train_y,\n",
    "    batch_size = 128,\n",
    "    epochs = 10,\n",
    "    validation_data = (test_x,test_y),\n",
    "    callbacks = [ValAccEarlyStopping(val_acc_base=0.98)],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1) , x_train data type:  float32\n",
      "x_test shape:  (10000, 28, 28, 1) , x_test data type:  float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "- load fashin_minist dataset\n",
    "- 10 classes 0-9\n",
    "'''\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "print('x_train shape: ',x_train.shape,', x_train data type: ', x_train.dtype)\n",
    "print('x_test shape: ',x_test.shape,', x_test data type: ',x_test.dtype)\n",
    " \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_train[258].reshape((28,28)).astype('float32'))\n",
    "plt.title('fashion_mnist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- data pipeline from Numpy Arrays\n",
    "- tf.data.Dataset.from_tensor_slices\n",
    "'''\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 10000\n",
    "tf.random.set_seed(5)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(batch_size).shuffle(shuffle_buffer_size)\n",
    "train_data = train_data.repeat()\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(batch_size).shuffle(shuffle_buffer_size)\n",
    "test_data = test_data.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (128, 28, 28, 1)\n",
      "y shape: (128,)\n",
      "x shape: (128, 28, 28, 1)\n",
      "y shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- data pipline from Numpy with iterator\n",
    "- tf.data.Dataset.from_tensor_slices\n",
    "- tf.compat.v1.data.make_one_shot_iteraor\n",
    "'''\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 10000\n",
    "tf.random.set_seed(5)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(batch_size).shuffle(shuffle_buffer_size)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(batch_size).shuffle(shuffle_buffer_size)\n",
    "train_iterator = tf.compat.v1.data.make_one_shot_iterator(train_data)\n",
    "test_iterator = tf.compat.v1.data.make_one_shot_iterator(test_data)\n",
    "\n",
    "tr_x,tr_y = train_iterator.get_next()\n",
    "print('x shape:',tr_x.shape)\n",
    "print('y shape:',tr_y.shape)\n",
    "te_x,te_y = test_iterator.get_next()\n",
    "print('x shape:',te_x.shape)\n",
    "print('y shape:',te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- data pipline from CSV file \n",
    "- tf.data.experimental.make_csv_dataset()\n",
    "- https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset#args\n",
    "'''\n",
    "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_data = pd.read_csv(titanic_file)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (OrderedDict([(age, (128,)), (fare, (128,)), (class, (128,))]), (128,)), types: (OrderedDict([(age, tf.float32), (fare, tf.float32), (class, tf.string)]), tf.int32)>\n",
      "'survived': [1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1\n",
      " 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0]\n",
      "features:\n",
      "  'age'               : [28.  36.  32.  45.  21.  28.  53.  10.  36.   9.  20.  28.  28.  49.\n",
      " 34.  30.  29.  11.  30.  70.  48.  30.  32.  28.  28.  23.  65.  43.\n",
      " 18.   2.  28.  15.  80.  28.  28.  28.  25.  51.  28.  16.  40.5 24.\n",
      " 28.  44.  33.  18.  28.  47.  57.  48.  61.  32.5 18.  44.  28.  50.\n",
      " 28.  42.  44.  25.  16.  29.  42.  22.  24.  35.  35.  19.   6.  27.\n",
      " 36.  33.  28.  24.  28.  28.  28.  28.  19.  40.   2.  24.  28.  28.\n",
      " 26.  36.  23.  37.  18.  39.  36.  39.  36.  19.  34.  28.  28.  20.\n",
      " 28.  44.   2.  24.  28.   3.  42.  42.  22.  28.  38.  28.  30.  33.\n",
      " 26.  28.  32.  31.  49.  17.  25.  40.  22.  21.  20.  19.  24.  22.\n",
      "  7.  32.5]\n",
      "  'fare'              : [  7.2292   0.       8.05    26.25     8.6625   7.8958  51.4792  27.9\n",
      " 135.6333  31.275    8.05     7.225   55.       0.      32.5     93.5\n",
      "   9.4833  46.9     24.15    71.      26.55     7.2292   7.8542  16.1\n",
      "   7.25    11.5     61.9792  26.25     7.8542  10.4625   7.8958 211.3375\n",
      "  30.      31.      69.55    16.1      7.8958   8.05   227.525    8.05\n",
      "  14.5     16.7      7.8958  26.      27.75     7.75    29.7     14.5\n",
      "  10.5     39.6     32.3208  13.     262.375   57.9792  30.6958  26.\n",
      "  23.45   227.525   90.      17.8      7.75    66.6     13.      49.5\n",
      "   7.4958  20.25     7.125    7.65    12.475   13.8583   7.8958   7.775\n",
      "   7.25     8.05    19.9667  15.5     82.1708  13.8625   7.8958  31.\n",
      "  21.075   79.2     33.      26.55     7.8958 120.      13.      29.7\n",
      "  17.8      0.      71.      83.1583   7.4958   7.775   26.55    23.25\n",
      "   7.7958   7.2292  79.2     16.1     39.6875  24.15    47.1     26.\n",
      "  52.      26.       9.35     7.7333  80.       7.8958  12.475    9.5\n",
      "  18.7875  25.4667  15.85    57.      25.9292 110.8833  26.       0.\n",
      "   7.25    73.5     15.7417  30.      13.       7.775   39.6875  30.0708]\n",
      "  'class'             : [b'Third' b'Third' b'Third' b'Second' b'Third' b'Third' b'First' b'Third'\n",
      " b'First' b'Third' b'Third' b'Third' b'First' b'Third' b'Second' b'First'\n",
      " b'Third' b'Third' b'Third' b'First' b'First' b'Third' b'Third' b'Third'\n",
      " b'Third' b'Second' b'First' b'Second' b'Third' b'Third' b'Third' b'First'\n",
      " b'First' b'First' b'Third' b'Third' b'Third' b'Third' b'First' b'Third'\n",
      " b'Third' b'Third' b'Third' b'Second' b'Second' b'Third' b'First' b'Third'\n",
      " b'Second' b'First' b'First' b'Second' b'First' b'First' b'First'\n",
      " b'Second' b'Third' b'First' b'First' b'Third' b'Third' b'First' b'Second'\n",
      " b'First' b'Third' b'Third' b'Third' b'Third' b'Third' b'Second' b'Third'\n",
      " b'Third' b'Third' b'Third' b'Third' b'Third' b'First' b'Second' b'Third'\n",
      " b'First' b'Third' b'First' b'Second' b'First' b'Third' b'First' b'Second'\n",
      " b'First' b'Third' b'First' b'First' b'First' b'Third' b'Third' b'First'\n",
      " b'Third' b'Third' b'Third' b'First' b'Third' b'Third' b'Third' b'First'\n",
      " b'Second' b'First' b'Second' b'Third' b'Third' b'First' b'Third' b'Third'\n",
      " b'Third' b'Third' b'Third' b'Third' b'First' b'First' b'First' b'Second'\n",
      " b'First' b'Third' b'Second' b'Third' b'First' b'Second' b'Third' b'Third'\n",
      " b'Second']\n"
     ]
    }
   ],
   "source": [
    "titanic_batches = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file, \n",
    "    batch_size=128,\n",
    "    label_name=\"survived\", \n",
    "    select_columns=['age','class', 'fare', 'survived'])\n",
    "print(titanic_batches)\n",
    "\n",
    "# for feature_batch, label_batch in titanic_batches.take(1):\n",
    "#     print(\"'survived': {}\".format(label_batch))\n",
    "#     print(\"features:\")\n",
    "#     for key, value in feature_batch.items():\n",
    "#         print(\"  {!r:20s}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/csv#train_evaluate_and_predict !!!!!!!!!!!!!!1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 468 steps, validate for 78 steps\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.4372 - acc: 0.8429 - val_loss: 0.4660 - val_acc: 0.8599\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 4s 10ms/step - loss: 0.2957 - acc: 0.8919 - val_loss: 0.3047 - val_acc: 0.8906\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.2603 - acc: 0.9035 - val_loss: 0.3023 - val_acc: 0.8891\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2345 - acc: 0.9135 - val_loss: 0.2691 - val_acc: 0.9007\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2133 - acc: 0.9209 - val_loss: 0.2664 - val_acc: 0.9061\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.1996 - acc: 0.9261 - val_loss: 0.2750 - val_acc: 0.9005\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.1876 - acc: 0.9308 - val_loss: 0.2538 - val_acc: 0.9101\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.1733 - acc: 0.9356 - val_loss: 0.2861 - val_acc: 0.9018\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.1616 - acc: 0.9396 - val_loss: 0.2620 - val_acc: 0.9094\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.1501 - acc: 0.9433 - val_loss: 0.2851 - val_acc: 0.9078\n",
      "Early stopping is not triggered, but best model is restored at epoch 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f66adc902d0>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- model training with data pipeline\n",
    "'''\n",
    "model = MyModel()\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics= ['acc'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = 10,\n",
    "    steps_per_epoch = x_train.shape[0]//batch_size,\n",
    "    validation_data = test_data,\n",
    "    validation_steps = x_test.shape[0]//batch_size,\n",
    "    callbacks = [ValAccEarlyStopping(val_acc_base=0.92)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
